{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the HybridAutoencoder architecture with LeakyReLU\n",
        "class HybridAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(8, 10),\n",
        "            nn.LeakyReLU(negative_slope=0.5),\n",
        "            nn.Linear(10, 8)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(8, 10),\n",
        "            nn.LeakyReLU(negative_slope=0.5),\n",
        "            nn.Linear(10, 8),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# Generate random dataset of 1000 8-bit binary sequences\n",
        "data = torch.randint(0, 2, (1000, 8)).float()\n",
        "dataset = TensorDataset(data, data)\n",
        "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = HybridAutoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.NAdam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Save the model parameters\n",
        "torch.save(model.state_dict(), 'hybrid_autoencoder_parameters.pth')\n",
        "\n",
        "# Verify the number of trainable parameters\n",
        "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Total Trainable Parameters: {trainable_parameters}')\n",
        "\n",
        "# Assuming the statement about 178 parameters per topology is a target to verify against\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnmzTktof7Ef",
        "outputId": "65a947ea-df8a-47f9-fc3f-4f079a01ecbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.23053038120269775\n",
            "Epoch 2, Loss: 0.18965253233909607\n",
            "Epoch 3, Loss: 0.12083496153354645\n",
            "Epoch 4, Loss: 0.13522782921791077\n",
            "Epoch 5, Loss: 0.09368416666984558\n",
            "Epoch 6, Loss: 0.09702236950397491\n",
            "Epoch 7, Loss: 0.10860507190227509\n",
            "Epoch 8, Loss: 0.030692970380187035\n",
            "Epoch 9, Loss: 0.06455062329769135\n",
            "Epoch 10, Loss: 0.047227878123521805\n",
            "Epoch 11, Loss: 0.04183494672179222\n",
            "Epoch 12, Loss: 0.008781780488789082\n",
            "Epoch 13, Loss: 0.0559607669711113\n",
            "Epoch 14, Loss: 0.07132793962955475\n",
            "Epoch 15, Loss: 0.018556276336312294\n",
            "Epoch 16, Loss: 0.0378124937415123\n",
            "Epoch 17, Loss: 0.07080216705799103\n",
            "Epoch 18, Loss: 0.006230912171304226\n",
            "Epoch 19, Loss: 0.01877507008612156\n",
            "Epoch 20, Loss: 0.016186052933335304\n",
            "Epoch 21, Loss: 0.0023237827699631453\n",
            "Epoch 22, Loss: 0.0059682405553758144\n",
            "Epoch 23, Loss: 0.03346540406346321\n",
            "Epoch 24, Loss: 0.0066977208480238914\n",
            "Epoch 25, Loss: 0.08269567787647247\n",
            "Epoch 26, Loss: 0.012625059112906456\n",
            "Epoch 27, Loss: 0.012640422210097313\n",
            "Epoch 28, Loss: 0.0003586467064451426\n",
            "Epoch 29, Loss: 0.003405333962291479\n",
            "Epoch 30, Loss: 0.02726450003683567\n",
            "Epoch 31, Loss: 0.030253583565354347\n",
            "Epoch 32, Loss: 0.019826019182801247\n",
            "Epoch 33, Loss: 0.044966310262680054\n",
            "Epoch 34, Loss: 0.00542111974209547\n",
            "Epoch 35, Loss: 0.003226680215448141\n",
            "Epoch 36, Loss: 0.03617570921778679\n",
            "Epoch 37, Loss: 0.006603421177715063\n",
            "Epoch 38, Loss: 0.0010862136259675026\n",
            "Epoch 39, Loss: 0.003189303446561098\n",
            "Epoch 40, Loss: 0.0033409507013857365\n",
            "Epoch 41, Loss: 0.003052295418456197\n",
            "Epoch 42, Loss: 0.010042267851531506\n",
            "Epoch 43, Loss: 0.003926672972738743\n",
            "Epoch 44, Loss: 0.004587692674249411\n",
            "Epoch 45, Loss: 0.0127381831407547\n",
            "Epoch 46, Loss: 0.00977481622248888\n",
            "Epoch 47, Loss: 0.0013811785029247403\n",
            "Epoch 48, Loss: 0.00012133489508414641\n",
            "Epoch 49, Loss: 0.006403824780136347\n",
            "Epoch 50, Loss: 0.00867144949734211\n",
            "Epoch 51, Loss: 8.985344175016508e-05\n",
            "Epoch 52, Loss: 0.0005085549782961607\n",
            "Epoch 53, Loss: 0.0007690272177569568\n",
            "Epoch 54, Loss: 0.0003634719760157168\n",
            "Epoch 55, Loss: 0.0017332707066088915\n",
            "Epoch 56, Loss: 0.002025927882641554\n",
            "Epoch 57, Loss: 0.0002574595855548978\n",
            "Epoch 58, Loss: 0.0007636963855475187\n",
            "Epoch 59, Loss: 0.0004153421032242477\n",
            "Epoch 60, Loss: 0.0037443977780640125\n",
            "Epoch 61, Loss: 0.00013071911234874278\n",
            "Epoch 62, Loss: 0.00010001302871387452\n",
            "Epoch 63, Loss: 5.857347423443571e-05\n",
            "Epoch 64, Loss: 0.00012692841119132936\n",
            "Epoch 65, Loss: 0.00016780175792519003\n",
            "Epoch 66, Loss: 0.00488357013091445\n",
            "Epoch 67, Loss: 0.004913832526654005\n",
            "Epoch 68, Loss: 0.005171062424778938\n",
            "Epoch 69, Loss: 0.0028859474696218967\n",
            "Epoch 70, Loss: 0.0033980607986450195\n",
            "Epoch 71, Loss: 0.00014953849313315004\n",
            "Epoch 72, Loss: 1.1938608395212214e-06\n",
            "Epoch 73, Loss: 0.00015363216516561806\n",
            "Epoch 74, Loss: 6.108144816607819e-07\n",
            "Epoch 75, Loss: 0.0016001317417249084\n",
            "Epoch 76, Loss: 2.4901668439269997e-05\n",
            "Epoch 77, Loss: 0.0026135207153856754\n",
            "Epoch 78, Loss: 0.0007574031478725374\n",
            "Epoch 79, Loss: 0.0015409274492412806\n",
            "Epoch 80, Loss: 1.0353758625569753e-05\n",
            "Epoch 81, Loss: 0.00013179608504287899\n",
            "Epoch 82, Loss: 0.00012664764653891325\n",
            "Epoch 83, Loss: 1.8929978978121653e-05\n",
            "Epoch 84, Loss: 0.0001185096480185166\n",
            "Epoch 85, Loss: 0.00010426880180602893\n",
            "Epoch 86, Loss: 4.0486240322934464e-05\n",
            "Epoch 87, Loss: 1.0068194569612388e-05\n",
            "Epoch 88, Loss: 7.352819375228137e-05\n",
            "Epoch 89, Loss: 3.142465357086621e-05\n",
            "Epoch 90, Loss: 1.5167302990448661e-05\n",
            "Epoch 91, Loss: 2.291421196787269e-06\n",
            "Epoch 92, Loss: 1.7049972029781202e-06\n",
            "Epoch 93, Loss: 0.025114184245467186\n",
            "Epoch 94, Loss: 0.00012204689846839756\n",
            "Epoch 95, Loss: 5.830534064443782e-07\n",
            "Epoch 96, Loss: 0.0002871086180675775\n",
            "Epoch 97, Loss: 8.697626299181138e-07\n",
            "Epoch 98, Loss: 0.002416625153273344\n",
            "Epoch 99, Loss: 0.00015324710693676025\n",
            "Epoch 100, Loss: 2.5524965167278424e-05\n",
            "Total Trainable Parameters: 356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 8-bit binary sequence\n",
        "test_input = torch.tensor([[0, 1, 0, 1, 1, 0, 1, 0]]).float()\n",
        "print(\"Test i/p : \", test_input)\n",
        "# Pass through the encoder only\n",
        "with torch.no_grad():  # Ensure no gradient is computed to save memory and computations\n",
        "    encrypted_vector = model.encoder(test_input)\n",
        "    print('Encrypted vector:', encrypted_vector.numpy())\n",
        "\n",
        "    decrypted_vector = model.decoder(encrypted_vector)\n",
        "    print('decrypted vector:', decrypted_vector.numpy())\n",
        "\n",
        "\n",
        "\n",
        "binarized_output = torch.where(decrypted_vector > 0.5, torch.tensor(1.0), torch.tensor(0.0))\n",
        "\n",
        "print('Binarized output:', binarized_output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BNSpTcHh7NS",
        "outputId": "d361b741-e002-42cc-935d-7020da3d2696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test i/p :  tensor([[0., 1., 0., 1., 1., 0., 1., 0.]])\n",
            "Encrypted vector: [[ 0.02202405  1.4976857  -1.5635588  -2.3500974  -1.4465282   9.93152\n",
            "  -3.9664261  -3.7735186 ]]\n",
            "decrypted vector: [[2.7782526e-05 1.0000000e+00 4.5347694e-11 9.9998927e-01 1.0000000e+00\n",
            "  4.1158108e-17 9.9999964e-01 3.5404420e-07]]\n",
            "Binarized output: tensor([[0., 1., 0., 1., 1., 0., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "correct_predictions = (binarized_output == test_input).float()\n",
        "\n",
        "# Calculate the accuracy as the mean of correct predictions\n",
        "accuracy = correct_predictions.mean()\n",
        "\n",
        "print(f'Accuracy: {accuracy.item() * 100}%')\n",
        "print(f'Correct predictions: {correct_predictions.sum().item()} out of {test_input.nelement()}')\n",
        "\n",
        "# You might also want to see the exact comparison\n",
        "comparison = torch.cat((test_input, binarized_output, correct_predictions), 0)\n",
        "print('Row 1: Original Input\\nRow 2: Binarized Output\\nRow 3: Correct Predictions (1: Correct, 0: Incorrect)\\n', comparison)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLJpb2_gjFdB",
        "outputId": "26786ae4-de7d-4765-eeb6-beae38e8ea7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.0%\n",
            "Correct predictions: 8.0 out of 8\n",
            "Row 1: Original Input\n",
            "Row 2: Binarized Output\n",
            "Row 3: Correct Predictions (1: Correct, 0: Incorrect)\n",
            " tensor([[0., 1., 0., 1., 1., 0., 1., 0.],\n",
            "        [0., 1., 0., 1., 1., 0., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataset\n",
        "torch.save(data, 'binary_sequences_dataset.pth')\n",
        "\n",
        "# Load the dataset\n",
        "loaded_data = torch.load('binary_sequences_dataset.pth')\n",
        "\n",
        "# Verify by comparing with original data (optional)\n",
        "print('Data loaded correctly:', torch.equal(data, loaded_data))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pMkNnudkc5C",
        "outputId": "8897ca2e-e2aa-4222-d650-bb755801c7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded correctly: True\n"
          ]
        }
      ]
    }
  ]
}